post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)
library(MASS)
n_grid <- 30
s_dens <- kde2d(s[,1], s[,2], 15, n=n_grid, lims = c(0,landscape_sizex,0,landscape_sizey))
persp(s_dens, phi = 20, theta = 195, d=5, xlab="x", ylab="y", expand = 0.5, ticktype = "detailed")
s_dens$y
library(MASS)
n_grid <- 31
s_dens <- kde2d(s[,1], s[,2], 15, n=n_grid, lims = c(0,landscape_sizex,0,landscape_sizey))
persp(s_dens, phi = 20, theta = 195, d=5, xlab="x", ylab="y", expand = 0.5, ticktype = "detailed")
s_dens$y
s_dens$x
s_dens$z[1:10,1:10]
appr <- interp.surface(s_dens, matrix(c(0,0,1,1,1.5,1.5,2,2), ncol=2))
L0 <- function(x, s) {
# just proportional to L0 loss.
-interp.surface(s_dens, matrix(c(x[1],x[2]), ncol=2))
}
loss_L0 <- normalize_0_1(grid_loss(L0, s))
draw_grid_loss(loss_L0, title="L0 loss")
point_estimate(loss_L0)
persp(s_dens, phi = 20, theta = 195, d=5, xlab="x", ylab="y", expand = 0.5, ticktype = "detailed")
normalize_0_1 <- function(x) {
(x-min(x))/(max(x)-min(x))
}
# compute the loss value for each cell in the grid landscape
grid_loss <- function(loss_function, s) {
f <- function(x,y) loss_function(c(x,y), s)
outer(1:landscape_sizex, 1:landscape_sizey, Vectorize(f))
}
# where is the minimum loss value?
point_estimate <- function(grid) {
which(grid == min(grid), arr.ind = TRUE)
}
# plot loss function
draw_grid_loss <- function(grid, title="Loss Function", pallete=c("blue","cyan"), n_colors=15) {
best_p <- point_estimate(grid)            # the best estimate (minimum loss)
best_loss <- grid[best_p[1], best_p[2]]   # its loss value
# plot the loss function in perspective
color <- colorRampPalette(pallete)(n_colors)
nrz <- nrow(grid)
ncz <- ncol(grid)
zfacet <- grid[-1, -1] + grid[-1, -ncz] + grid[-nrz, -1] + grid[-nrz, -ncz]
facetcol <- cut(zfacet, n_colors)
p_plot <- persp(grid, phi = 20, theta = 195, d=5, expand = 0.5,
xlab="x", ylab="y", zlab="loss", col = color[facetcol], main=title)
# dot where's the minimum loss
points(trans3d(best_p[1]/landscape_sizex, best_p[2]/landscape_sizey, best_loss, pmat = p_plot), col = 2, pch = 16)
}
loss_L2 <- normalize_0_1(grid_loss(L2, s))
draw_grid_loss(loss_L2, title="L2 loss")
point_estimate(loss_L2)
loss_L1 <- normalize_0_1(grid_loss(L1, s))
draw_grid_loss(loss_L1, title="L1 loss")
point_estimate(loss_L1)
ss
norm(c(1,2),"F")
sqrt(5)
L2 <- function(x, s) {
sum(apply(s,1,function(si) norm((si-x),"F")))
}
point_estimate(loss_L2)
loss_L2 <- normalize_0_1(grid_loss(L2, s))
L2 <- function(x, s) {
sum(apply(s,1,function(si) sqrt(sum((si-x)^2))))
}
loss_L2 <- normalize_0_1(grid_loss(L2, s))
draw_grid_loss(loss_L2, title="L2 loss")
point_estimate(loss_L2)
L1 <- function(x, s) {
sum(c(abs(x[1]-s[,1]),abs(x[2]-s[,2])))
}
L2 <- function(x, s) {
sum(apply(s,1,function(si) sum((si-x)^2)))
}
loss_L0 <- normalize_0_1(grid_loss(L0, s))
draw_grid_loss(loss_L0, title="L0 loss")
point_estimate(loss_L0)
loss_L1 <- normalize_0_1(grid_loss(L1, s))
draw_grid_loss(loss_L1, title="L1 loss")
point_estimate(loss_L1)
loss_L2 <- normalize_0_1(grid_loss(L2, s))
draw_grid_loss(loss_L2, title="L2 loss")
point_estimate(loss_L2)
library(mvtnorm) # rmvnorm
landscape_sizex <- 60  # the size of the landscape
landscape_sizey <- 30
# build a posterior sample
posterior_sample <- function(n) {
dist_i <- sample(3, n, replace = TRUE, c(18, 27, 55)) # from which distribution to sample
# params of the three distributions
mu_x <- c(40, 15, 25)
mu_y <- c(15, 25, 10)
mu <- matrix(c(mu_x,mu_y),ncol=2)
sigma <- c(c(25,5,5,1), 4*diag(2), 0.05*c(9,-3,-3,1))
dim(sigma) <- c(2,2,3)
# create the posterior sample
post <- matrix(rep(NA,2*n), ncol=2)
for (i in 1:n)
post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)  # the available posterior sample
library(mvtnorm) # rmvnorm
landscape_sizex <- 60  # the size of the landscape
landscape_sizey <- 30
# build a posterior sample
posterior_sample <- function(n) {
dist_i <- sample(3, n, replace = TRUE, c(18, 27, 55)) # from which distribution to sample
# params of the three distributions
mu_x <- c(40, 15, 25)
mu_y <- c(15, 25, 10)
mu <- matrix(c(mu_x,mu_y),ncol=2)
sigma <- c(c(25,5,5,1), 4*diag(2), 0.1*c(9,-3,-3,1))
dim(sigma) <- c(2,2,3)
# create the posterior sample
post <- matrix(rep(NA,2*n), ncol=2)
for (i in 1:n)
post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)  # the available posterior sample
library(mvtnorm) # rmvnorm
landscape_sizex <- 60  # the size of the landscape
landscape_sizey <- 30
# build a posterior sample
posterior_sample <- function(n) {
dist_i <- sample(3, n, replace = TRUE, c(18, 27, 55)) # from which distribution to sample
# params of the three distributions
mu_x <- c(40, 15, 25)
mu_y <- c(15, 25, 10)
mu <- matrix(c(mu_x,mu_y),ncol=2)
sigma <- c(c(25,5,5,1), 4*diag(2), 0.1*diag(1))
dim(sigma) <- c(2,2,3)
# create the posterior sample
post <- matrix(rep(NA,2*n), ncol=2)
for (i in 1:n)
post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)  # the available posterior sample
library(mvtnorm) # rmvnorm
landscape_sizex <- 60  # the size of the landscape
landscape_sizey <- 30
# build a posterior sample
posterior_sample <- function(n) {
dist_i <- sample(3, n, replace = TRUE, c(18, 27, 55)) # from which distribution to sample
# params of the three distributions
mu_x <- c(40, 15, 25)
mu_y <- c(15, 25, 10)
mu <- matrix(c(mu_x,mu_y),ncol=2)
sigma <- c(c(25,5,5,1), 4*diag(2), 0.1*diag(2))
dim(sigma) <- c(2,2,3)
# create the posterior sample
post <- matrix(rep(NA,2*n), ncol=2)
for (i in 1:n)
post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)  # the available posterior sample
library(MASS)
n_grid <- 31
s_dens <- kde2d(s[,1], s[,2], 15, n=n_grid, lims = c(0,landscape_sizex,0,landscape_sizey))
persp(s_dens, phi = 20, theta = 195, d=5, xlab="x", ylab="y", expand = 0.5, ticktype = "detailed")
library(mvtnorm) # rmvnorm
landscape_sizex <- 60  # the size of the landscape
landscape_sizey <- 30
# build a posterior sample
posterior_sample <- function(n) {
dist_i <- sample(3, n, replace = TRUE, c(18, 27, 55)) # from which distribution to sample
# params of the three distributions
mu_x <- c(40, 15, 25)
mu_y <- c(15, 25, 10)
mu <- matrix(c(mu_x,mu_y),ncol=2)
sigma <- c(c(25,5,5,1), 4*diag(2), 0.01*diag(2))
dim(sigma) <- c(2,2,3)
# create the posterior sample
post <- matrix(rep(NA,2*n), ncol=2)
for (i in 1:n)
post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)  # the available posterior sample
library(MASS)
n_grid <- 31
s_dens <- kde2d(s[,1], s[,2], 15, n=n_grid, lims = c(0,landscape_sizex,0,landscape_sizey))
persp(s_dens, phi = 20, theta = 195, d=5, xlab="x", ylab="y", expand = 0.5, ticktype = "detailed")
library(mvtnorm) # rmvnorm
landscape_sizex <- 60  # the size of the landscape
landscape_sizey <- 30
# build a posterior sample
posterior_sample <- function(n) {
dist_i <- sample(3, n, replace = TRUE, c(18, 55, 27)) # from which distribution to sample
# params of the three distributions
mu_x <- c(40, 15, 25)
mu_y <- c(15, 25, 10)
mu <- matrix(c(mu_x,mu_y),ncol=2)
sigma <- c(c(25,5,5,1), 4*diag(2), 0.01*diag(2))
dim(sigma) <- c(2,2,3)
# create the posterior sample
post <- matrix(rep(NA,2*n), ncol=2)
for (i in 1:n)
post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)  # the available posterior sample
library(MASS)
n_grid <- 31
s_dens <- kde2d(s[,1], s[,2], 15, n=n_grid, lims = c(0,landscape_sizex,0,landscape_sizey))
persp(s_dens, phi = 20, theta = 195, d=5, xlab="x", ylab="y", expand = 0.5, ticktype = "detailed")
library(mvtnorm) # rmvnorm
landscape_sizex <- 60  # the size of the landscape
landscape_sizey <- 30
# build a posterior sample
posterior_sample <- function(n) {
dist_i <- sample(3, n, replace = TRUE, c(55, 18, 27)) # from which distribution to sample
# params of the three distributions
mu_x <- c(40, 15, 25)
mu_y <- c(15, 25, 10)
mu <- matrix(c(mu_x,mu_y),ncol=2)
sigma <- c(c(25,5,5,1), 4*diag(2), 0.01*diag(2))
dim(sigma) <- c(2,2,3)
# create the posterior sample
post <- matrix(rep(NA,2*n), ncol=2)
for (i in 1:n)
post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)  # the available posterior sample
library(MASS)
n_grid <- 31
s_dens <- kde2d(s[,1], s[,2], 15, n=n_grid, lims = c(0,landscape_sizex,0,landscape_sizey))
persp(s_dens, phi = 20, theta = 195, d=5, xlab="x", ylab="y", expand = 0.5, ticktype = "detailed")
library(mvtnorm) # rmvnorm
landscape_sizex <- 60  # the size of the landscape
landscape_sizey <- 30
# build a posterior sample
posterior_sample <- function(n) {
dist_i <- sample(3, n, replace = TRUE, c(55, 18, 27)) # from which distribution to sample
# params of the three distributions
mu_x <- c(40, 15, 25)
mu_y <- c(15, 25, 10)
mu <- matrix(c(mu_x,mu_y),ncol=2)
sigma <- c(0.1*c(25,5,5,1), 4*diag(2), 0.01*diag(2))
dim(sigma) <- c(2,2,3)
# create the posterior sample
post <- matrix(rep(NA,2*n), ncol=2)
for (i in 1:n)
post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)  # the available posterior sample
library(MASS)
n_grid <- 31
s_dens <- kde2d(s[,1], s[,2], 15, n=n_grid, lims = c(0,landscape_sizex,0,landscape_sizey))
persp(s_dens, phi = 20, theta = 195, d=5, xlab="x", ylab="y", expand = 0.5, ticktype = "detailed")
library(mvtnorm) # rmvnorm
landscape_sizex <- 60  # the size of the landscape
landscape_sizey <- 30
# build a posterior sample
posterior_sample <- function(n) {
dist_i <- sample(3, n, replace = TRUE, c(35, 18, 47)) # from which distribution to sample
# params of the three distributions
mu_x <- c(40, 15, 25)
mu_y <- c(15, 25, 10)
mu <- matrix(c(mu_x,mu_y),ncol=2)
sigma <- c(0.1*c(25,5,5,1), 4*diag(2), 0.01*diag(2))
dim(sigma) <- c(2,2,3)
# create the posterior sample
post <- matrix(rep(NA,2*n), ncol=2)
for (i in 1:n)
post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)  # the available posterior sample
library(MASS)
n_grid <- 31
s_dens <- kde2d(s[,1], s[,2], 15, n=n_grid, lims = c(0,landscape_sizex,0,landscape_sizey))
persp(s_dens, phi = 20, theta = 195, d=5, xlab="x", ylab="y", expand = 0.5, ticktype = "detailed")
library(mvtnorm) # rmvnorm
landscape_sizex <- 60  # the size of the landscape
landscape_sizey <- 30
# build a posterior sample
posterior_sample <- function(n) {
dist_i <- sample(3, n, replace = TRUE, c(35, 18, 47)) # from which distribution to sample
# params of the three distributions
mu_x <- c(40, 15, 25)
mu_y <- c(15, 25, 10)
mu <- matrix(c(mu_x,mu_y),ncol=2)
sigma <- c(2*diag(2), 4*diag(2), 15*diag(2))
dim(sigma) <- c(2,2,3)
# create the posterior sample
post <- matrix(rep(NA,2*n), ncol=2)
for (i in 1:n)
post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)  # the available posterior sample
library(MASS)
n_grid <- 31
s_dens <- kde2d(s[,1], s[,2], 15, n=n_grid, lims = c(0,landscape_sizex,0,landscape_sizey))
persp(s_dens, phi = 20, theta = 195, d=5, xlab="x", ylab="y", expand = 0.5, ticktype = "detailed")
library(mvtnorm) # rmvnorm
landscape_sizex <- 60  # the size of the landscape
landscape_sizey <- 30
# build a posterior sample
posterior_sample <- function(n) {
dist_i <- sample(3, n, replace = TRUE, c(32, 18, 50)) # from which distribution to sample
# params of the three distributions
mu_x <- c(40, 15, 25)
mu_y <- c(15, 25, 10)
mu <- matrix(c(mu_x,mu_y),ncol=2)
sigma <- c(2*diag(2), 4*diag(2), 15*diag(2))
dim(sigma) <- c(2,2,3)
# create the posterior sample
post <- matrix(rep(NA,2*n), ncol=2)
for (i in 1:n)
post[i,] <- rmvnorm(1, mean=mu[dist_i[i],], sigma=sigma[,,dist_i[i]])
post <- post[post[,1] >= 0 & post[,1] <= landscape_sizex,]
post[post[,2] >= 0 & post[,2] <= landscape_sizey,]
}
s <- posterior_sample(5e3)  # the available posterior sample
library(MASS)
n_grid <- 31
s_dens <- kde2d(s[,1], s[,2], 15, n=n_grid, lims = c(0,landscape_sizex,0,landscape_sizey))
persp(s_dens, phi = 20, theta = 195, d=5, xlab="x", ylab="y", expand = 0.5, ticktype = "detailed")
loss_L0 <- normalize_0_1(grid_loss(L0, s))
draw_grid_loss(loss_L0, title="L0 loss")
point_estimate(loss_L0)
loss_L1 <- normalize_0_1(grid_loss(L1, s))
draw_grid_loss(loss_L1, title="L1 loss")
point_estimate(loss_L1)
loss_L2 <- normalize_0_1(grid_loss(L2, s))
draw_grid_loss(loss_L2, title="L2 loss")
point_estimate(loss_L2)
choose(!7,6)
choose(17,6)
choose(17,11)
install.packages("rstan")
install.packages("RStan")
Sys.setenv(MAKEFLAGS = "-j4")
source('http://mc-stan.org/rstan/install.R', echo = TRUE, max.deparse.length = 2000)
install_rstan()
library(rstan)
model <- '
functions {
real lincoln_log(vector D, real n, real p1, real p2) {
real k1; real k2; real c;
real choose1; real binom1; real binom2; real choose2; real choose3;
k1 <- D[1]; k2 <- D[2]; c <- D[3];
choose1 <- exp( lgamma(n+1)    - (lgamma(k1+1)   + lgamma(n-k1+1)) );
binom1  <- pow(p1, k1) * pow(1-p1, n-k1);
choose2 <- exp( lgamma(k1+1)   - (lgamma(c+1)    + lgamma(k1-c+1)) );
choose3 <- exp( lgamma(n-k1+1) - (lgamma(k2-c+1) + lgamma(n-k1-k2+c+1)) );
binom2  <- pow(p2, k2) * pow(1-p2, n-k2);
return log( choose1 * binom1 * choose2 * choose3 * binom2 );
}
}
data {
int<lower=0>  k1;   // bugs found by tester 1
int<lower=0>  k2;   // bugs found by tester 2
int<lower=0>  c;    // number of common bugs
}
transformed data {
int<lower=0>  m1;   // lower bound for n
int<lower=0>  m2;   // upper bound for n
vector[3] D;
m1 <- k1+k2-c;
m2 <- 350;
D[1] <- k1; D[2] <- k2; D[3] <- c;
}
parameters {
real<lower=m1, upper=m2> n;   // the number of total bugs
real<lower=0, upper=1>  p1;   // performance of tester 1
real<lower=0, upper=1>  p2;   // performance of tester 2
}
model {
n  ~ uniform(m1,m2);   // priors
p1 ~ uniform(0,1);
p2 ~ uniform(0,1);
D ~ lincoln(n,p1,p2);  // likelihood, equivalent to: increment_log_prob(lincoln_log(D,n,p1,p2));
}
'
fit  <- stan(model_code = model, data = list(k1=20, k2=15, c=3), iter = 1000,  chains = 4, verbose = FALSE)
fit2 <- stan(fit = fit,          data = list(k1=20, k2=15, c=3), iter = 50000, chains = 4, verbose = FALSE, seed=101, warmup=5000)
print(fit2)
la <- extract(fit2, permuted = TRUE)
hist(as.vector(la$n), breaks=100, prob=TRUE, xlab="Number of bugs", main="Posterior p(n|D)")
dst <- density(la$n)
lines(dst, col="red", lwd=2)
stan.n.bugs <- dst$x[which.max(dst$y)]    # get the MAP from the estimated density
stan.n.bugs
install.packages("rjags")
library(rjags)
data(LINE)
LINE$recompile()
LINE.samples <- jags.samples(LINE, c("alpha","beta","sigma"),
n.iter=1000)
LINE.samples
library(BRugs)
run.model <- function(model, samples, data=list(), chainLength=10000, burnin=0.10, init.func, n.chains=1) {
writeLines(model, con="model.txt")  # Write the modelString to a file
modelCheck( "model.txt" )           # Send the model to BUGS, which checks the model syntax
if (length(data)>0)                 # If there's any data available...
modelData(bugsData(data))         # ... BRugs puts it into a file and ships it to BUGS
modelCompile(n.chains)              # BRugs command tells BUGS to compile the model
if (missing(init.func)) {
modelGenInits()                   # BRugs command tells BUGS to randomly initialize a chain
} else {
for (chain in 1:n.chains) {       # otherwise use user's init data
modelInits(bugsInits(init.func))
}
}
modelUpdate(chainLength*burnin)     # Burn-in period to be discarded
samplesSet(samples)                 # BRugs tells BUGS to keep a record of the sampled values
modelUpdate(chainLength)            # BRugs command tells BUGS to randomly initialize a chain
}
install.packages("BRugs")
library(BRugs)
run.model <- function(model, samples, data=list(), chainLength=10000, burnin=0.10, init.func, n.chains=1) {
writeLines(model, con="model.txt")  # Write the modelString to a file
modelCheck( "model.txt" )           # Send the model to BUGS, which checks the model syntax
if (length(data)>0)                 # If there's any data available...
modelData(bugsData(data))         # ... BRugs puts it into a file and ships it to BUGS
modelCompile(n.chains)              # BRugs command tells BUGS to compile the model
if (missing(init.func)) {
modelGenInits()                   # BRugs command tells BUGS to randomly initialize a chain
} else {
for (chain in 1:n.chains) {       # otherwise use user's init data
modelInits(bugsInits(init.func))
}
}
modelUpdate(chainLength*burnin)     # Burn-in period to be discarded
samplesSet(samples)                 # BRugs tells BUGS to keep a record of the sampled values
modelUpdate(chainLength)            # BRugs command tells BUGS to randomly initialize a chain
}
modelString = "
model {
# Likelihood function
phi <- -log(choose1 * binom1 * choose2 * choose3 * binom2) + CZERO
dummy <- 0
dummy ~ dpois( phi )
CZERO <- 1000000    # for the zero's trick
# compute binomial coefficients
# cf. http://stats.stackexchange.com/questions/62418/binomial-coefficient-in-jags
choose1 <- exp( loggam(n+1) - (loggam(k1+1) + loggam(n-k1+1)) )           # choose(n,k1)
binom1  <- pow(p1, k1) * pow(1-p1, n-k1)
choose2 <- exp( loggam(k1+1) - (loggam(c+1) + loggam(k1-c+1)) )           # choose(k1,c)
choose3 <- exp( loggam(n-k1+1) - (loggam(k2-c+1) + loggam(n-k1-k2+c+1)) ) # choose(n-k1,k2-c)
binom2  <- pow(p2, k2) * pow(1-p2, n-k2)
# Priors
p1 ~ dunif(0,1)
p2 ~ dunif(0,1)
n  ~ dunif(m1,m2)         # uniform prior
#n ~ dexp(0.001)I(m1,m2)  # truncated exponential prior (another option for the prior of n)
# Some needed constants
m1 <- k1+k2-c    # the minimum possible number of errors
m2 <- 350        # we don't know the max, but let's allow some breathing space
}
"
# data
k1 <- 20 # the input from the problem
k2 <- 15
c  <- 3
# initializations (with some more boilerplate)
genInitFactory <- function()  {
i <- 0
function() {
i <<- i + 1
list(
p1 = 0.5,
p2 = 0.5,
n  = k1*k2/c # let's start with the Lincoln index estimate
)
}
}
# Everything is ready. Run the model!
run.model(modelString, samples=c("n","p1","p2"), data=list(k1=k1,k2=k2,c=c), chainLength=2e5, init.func=genInitFactory())
# data
k1 <- 20 # the input from the problem
k2 <- 15
c  <- 3
# initializations (with some more boilerplate)
genInitFactory <- function()  {
i <- 0
function() {
i <<- i + 1
list(
p1 = 0.5,
p2 = 0.5,
n  = k1*k2/c # let's start with the Lincoln index estimate
)
}
}
# Everything is ready. Run the model!
run.model(modelString, samples=c("n","p1","p2"), data=list(k1=k1,k2=k2,c=c), chainLength=2e5, init.func=genInitFactory())
setwd("C:/Users/jpn.INFORMATICA/Dropbox/My Work/Projects/R/Markdowns/bugs")
run.model(modelString, samples=c("n","p1","p2"), data=list(k1=k1,k2=k2,c=c), chainLength=2e5, init.func=genInitFactory())
